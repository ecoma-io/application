name: ecoma-dev-infras

volumes:
  postgres_data:
  minio_data:

networks:
  ecomma:
    name: ecomma-dev
    driver: bridge
    ipam:
      config:
        - subnet: 10.10.10.0/24
          gateway: 10.10.10.1

services:
  nginx:
    image: nginx:alpine
    container_name: nginx
    ports:
      - 443:443
      - 80:80
    volumes:
      - .docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - .docker/nginx/certs:/certs:ro
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      ecomma:
        ipv4_address: 10.10.10.10
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "-q",
          "--spider",
          "--no-check-certificate",
          "https://fbi.com",
        ]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 10s

  maildev:
    image: maildev/maildev
    container_name: maildev
    restart: always
    ports:
      - "1080:1080" # Web UI
      - "1025:1025" # SMTP Server
    environment:
      - MAILDEV_INCOMING_USER=admin
      - MAILDEV_INCOMING_PASS=password
    networks:
      ecomma:
        ipv4_address: 10.10.10.20
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:1080"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 10s

  postgres:
    image: postgres:15
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: database
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - .docker/postgres/init.sql:/docker-entrypoint-initdb.d/init-database.sql
    networks:
      ecomma:
        ipv4_address: 10.10.10.30
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d database"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 15s

  postgres-admin:
    image: adminer:4.8.1
    container_name: postgres-admin
    ports:
      - "8080:8080"
    volumes:
      - .docker/postgres/adminer-auto-login.php:/var/www/html/plugins-enabled/adminer-auto-login.php
    networks:
      ecomma:
        ipv4_address: 10.10.10.40
    depends_on:
      postgres:
        condition: service_healthy

  minio:
    image: minio/minio
    container_name: minio
    restart: always
    ports:
      - "9000:9000" # API S3
      - "9090:9090" # Web UI
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9090"
    volumes:
      - minio_data:/data
    networks:
      ecomma:
        ipv4_address: 10.10.10.50
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 10s

  create-bucket:
    image: minio/mc
    container_name: create-bucket
    restart: on-failure
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      sleep 5;
      mc alias set minio http://minio:9000 minioadmin minioadmin;
      mc ls minio/assets || mc mb minio/assets;
      mc anonymous set public minio/assets;
      mc ls minio/private || mc mb minio/private;
      mc anonymous set none minio/private;
      echo 'Bucket created!';
      "
    networks:
      ecomma:
        ipv4_address: 10.10.10.51

  kratos-migrate:
    image: oryd/kratos:v1.3.1
    container_name: kratos-migrate
    restart: on-failure
    depends_on:
      postgres:
        condition: service_healthy
    command: -c /etc/config/kratos.yml migrate sql -e --yes
    environment:
      - DSN=postgres://user:password@postgres:5432/kratos?sslmode=disable
    volumes:
      - .docker/kratos/kratos.yml:/etc/config/kratos.yml
      - .docker/kratos/identity.schema.json:/etc/config/identity.schema.json
    networks:
      ecomma:
        ipv4_address: 10.10.10.60

  kratos:
    image: oryd/kratos:v1.3.1
    container_name: kratos
    restart: always
    depends_on:
      kratos-migrate:
        condition: service_completed_successfully
    ports:
      - "4433:4433" # Public API
      - "4434:4434" # Admin API
    command: serve -c /etc/config/kratos.yml --dev --watch-courier
    environment:
      - DSN=postgres://user:password@postgres:5432/kratos?sslmode=disable&max_conns=20&max_idle_conns=4
      - LOG_LEVEL=trace
    volumes:
      - .docker/kratos/kratos.yml:/etc/config/kratos.yml
      - .docker/kratos/identity.schema.json:/etc/config/identity.schema.json
    networks:
      ecomma:
        ipv4_address: 10.10.10.61
    healthcheck:
      test:
        ["CMD", "wget", "-q", "--spider", "http://localhost:4433/health/alive"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 10s

  hydra-migrate:
    image: oryd/hydra:v2.3.0
    container_name: hydra-migrate
    restart: on-failure
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - DSN=postgres://user:password@postgres:5432/hydra?sslmode=disable
    command: migrate sql -e --yes
    networks:
      ecomma:
        ipv4_address: 10.10.10.70

  hydra:
    image: oryd/hydra:v2.3.0
    container_name: hydra
    restart: always
    depends_on:
      hydra-migrate:
        condition: service_completed_successfully
    ports:
      - "4444:4444" # Public API
      - "4445:4445" # Admin API
    environment:
      - DSN=postgres://user:password@postgres:5432/hydra?sslmode=disable
      - URLS_SELF_ISSUER=http://localhost:4444
      - URLS_CONSENT=http://localhost:4201/consent
      - URLS_LOGIN=http://localhost:4201/login
      - SECRETS_SYSTEM=system-secret-key
      - LOG_LEVEL=debug
    command: serve all --dev
    networks:
      ecomma:
        ipv4_address: 10.10.10.71
    healthcheck:
      test:
        ["CMD", "wget", "-q", "--spider", "http://localhost:4444/health/alive"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 10s

  keto-migrate:
    image: oryd/keto:v0.14.0
    container_name: keto-migrate
    restart: on-failure
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - DSN=postgres://user:password@postgres:5432/keto?sslmode=disable
    volumes:
      - .docker/keto/keto.yaml:/etc/config/keto.yaml
    command: -c /etc/config/keto.yaml migrate up --yes
    networks:
      ecomma:
        ipv4_address: 10.10.10.80

  keto:
    image: oryd/keto:v0.14.0
    container_name: keto
    restart: always
    depends_on:
      keto-migrate:
        condition: service_completed_successfully
    environment:
      - DSN=postgres://user:password@postgres:5432/keto?sslmode=disable
    command: serve -c /etc/config/keto.yaml
    ports:
      - "4466:4466" # Read API
      - "4467:4467" # Write API
    volumes:
      - .docker/keto/keto.yaml:/etc/config/keto.yaml
    networks:
      ecomma:
        ipv4_address: 10.10.10.81
    healthcheck:
      test:
        ["CMD", "wget", "-q", "--spider", "http://localhost:4466/health/ready"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 10s

  oathkeeper:
    image: oryd/oathkeeper:v0.40.9
    container_name: oathkeeper
    restart: always
    depends_on:
      hydra:
        condition: service_healthy
    environment:
      - LOG_LEVEL=debug
      - MUTATORS_ID_TOKEN_ISSUER_URL=http://localhost:4444
      - AUTHENTICATORS_OAUTH2_INTROSPECTION_CLIENT_ID=oathkeeper-client
      - AUTHENTICATORS_OAUTH2_INTROSPECTION_CLIENT_SECRET=oathkeeper-secret
      - AUTHENTICATORS_OAUTH2_INTROSPECTION_INTROSPECTION_URL=http://hydra:4445/oauth2/introspect
      - AUTHORIZERS_KETO_ENGINE_ACPORY_KETO_READ_REMOTE=http://keto:4466
    volumes:
      - .docker/oathkeeper/rules.json:/etc/oathkeeper/rules.json
    ports:
      - "4455:4455" # Proxy API
      - "4456:4456" # API quản lý
    command: serve proxy --config /etc/oathkeeper/rules.json
    networks:
      ecomma:
        ipv4_address: 10.10.10.90
    healthcheck:
      test:
        ["CMD", "wget", "-q", "--spider", "http://localhost:4456/health/alive"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 10s

  home-site:
    image: ghcr.io/ecoma-io/home-site
    container_name: home-site
    pull_policy: if_not_present
    restart: always
    networks:
      ecomma:
        ipv4_address: 10.10.10.100

  accounts-site:
    image: ghcr.io/ecoma-io/accounts-site
    container_name: accounts-site
    pull_policy: if_not_present
    restart: always
    networks:
      ecomma:
        ipv4_address: 10.10.10.110

  app-site:
    image: ghcr.io/ecoma-io/app-site
    container_name: app-site
    pull_policy: if_not_present
    restart: always
    networks:
      ecomma:
        ipv4_address: 10.10.10.120
